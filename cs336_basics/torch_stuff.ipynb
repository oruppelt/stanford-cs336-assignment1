{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21db1a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d3a5e32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_k = 50\n",
    "device='cpu'\n",
    "theta = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2df1a051",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13.,\n",
       "        14., 15., 16., 17., 18., 19., 20., 21., 22., 23., 24.])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(0, d_k // 2, dtype=torch.float32, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0acf077d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "        18, 19, 20, 21, 22, 23, 24])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_indices = torch.arange(0, d_k//2, device = device)\n",
    "k_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "20818883",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.0000,  1.2023,  1.4454,  1.7378,  2.0893,  2.5119,  3.0200,  3.6308,\n",
       "         4.3652,  5.2481,  6.3096,  7.5858,  9.1201, 10.9648, 13.1826, 15.8489,\n",
       "        19.0546, 22.9087, 27.5423, 33.1131, 39.8107, 47.8630, 57.5440, 69.1831,\n",
       "        83.1764])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freqs = theta**(2 * k_indices / d_k)\n",
    "freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "37b5a117",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13.,\n",
       "        14., 15., 16., 17., 18., 19.])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(20, dtype=torch.float32, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec4f09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.outer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bccc9684",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ -1.0000,  -1.2023,  -1.4454,  -1.7378,  -2.0893,  -2.5119,  -3.0200,\n",
       "         -3.6308,  -4.3652,  -5.2481,  -6.3096,  -7.5858,  -9.1201, -10.9648,\n",
       "        -13.1826, -15.8489, -19.0546, -22.9087, -27.5423, -33.1131, -39.8107,\n",
       "        -47.8630, -57.5440, -69.1831, -83.1764])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freqs_neg = -1 * freqs\n",
    "freqs_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4d960d02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  1.0000,  -1.0000],\n",
       "        [  1.2023,  -1.2023],\n",
       "        [  1.4454,  -1.4454],\n",
       "        [  1.7378,  -1.7378],\n",
       "        [  2.0893,  -2.0893],\n",
       "        [  2.5119,  -2.5119],\n",
       "        [  3.0200,  -3.0200],\n",
       "        [  3.6308,  -3.6308],\n",
       "        [  4.3652,  -4.3652],\n",
       "        [  5.2481,  -5.2481],\n",
       "        [  6.3096,  -6.3096],\n",
       "        [  7.5858,  -7.5858],\n",
       "        [  9.1201,  -9.1201],\n",
       "        [ 10.9648, -10.9648],\n",
       "        [ 13.1826, -13.1826],\n",
       "        [ 15.8489, -15.8489],\n",
       "        [ 19.0546, -19.0546],\n",
       "        [ 22.9087, -22.9087],\n",
       "        [ 27.5423, -27.5423],\n",
       "        [ 33.1131, -33.1131],\n",
       "        [ 39.8107, -39.8107],\n",
       "        [ 47.8630, -47.8630],\n",
       "        [ 57.5440, -57.5440],\n",
       "        [ 69.1831, -69.1831],\n",
       "        [ 83.1764, -83.1764]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack([freqs, freqs_neg], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fdb5478f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_even_rot shape: torch.Size([2, 4, 3])\n",
      "x_odd_rot shape: torch.Size([2, 4, 3])\n",
      "Target shape: (2, 4, 6)\n",
      "\n",
      "==================================================\n",
      "METHOD 1: Direct indexing (most efficient)\n",
      "==================================================\n",
      "Result1 shape: torch.Size([2, 4, 6])\n",
      "\n",
      "==================================================\n",
      "METHOD 2: Stack + flatten (your approach fixed)\n",
      "==================================================\n",
      "Stacked shape: torch.Size([2, 4, 3, 2])\n",
      "Result2 shape: torch.Size([2, 4, 6])\n",
      "\n",
      "==================================================\n",
      "METHOD 3: Stack + reshape\n",
      "==================================================\n",
      "Result3 shape: torch.Size([2, 4, 6])\n",
      "\n",
      "==================================================\n",
      "METHOD 4: Concatenate + rearrange (using einops)\n",
      "==================================================\n",
      "Result4 shape: torch.Size([2, 4, 6])\n",
      "\n",
      "==================================================\n",
      "METHOD 5: Interleave using repeat_interleave\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "VERIFICATION: All methods give same result?\n",
      "==================================================\n",
      "Method 1 == Method 2: True\n",
      "Method 1 == Method 3: True\n",
      "Method 1 == Method 4: True\n",
      "\n",
      "==================================================\n",
      "ELEMENT ORDER VERIFICATION\n",
      "==================================================\n",
      "First few elements of result1:\n",
      "Should be: even[0], odd[0], even[1], odd[1], even[2], odd[2]\n",
      "result1[0, 0, :]: tensor([ 1.8610, -1.4852, -1.3570,  0.9508,  1.7945,  1.1790])\n",
      "x_even_rot[0, 0, :]: tensor([ 1.8610, -1.3570,  1.7945])\n",
      "x_odd_rot[0, 0, :]: tensor([-1.4852,  0.9508,  1.1790])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def demo_merge_techniques():\n",
    "    # Example: d_k = 6, so d_k/2 = 3\n",
    "    batch_size, seq_len, d_k = 2, 4, 6\n",
    "    \n",
    "    # Simulate rotated even and odd elements\n",
    "    x_even_rot = torch.randn(batch_size, seq_len, d_k // 2)  # Shape: (2, 4, 3)\n",
    "    x_odd_rot = torch.randn(batch_size, seq_len, d_k // 2)   # Shape: (2, 4, 3)\n",
    "    \n",
    "    print(f\"x_even_rot shape: {x_even_rot.shape}\")\n",
    "    print(f\"x_odd_rot shape: {x_odd_rot.shape}\")\n",
    "    print(f\"Target shape: ({batch_size}, {seq_len}, {d_k})\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"METHOD 1: Direct indexing (most efficient)\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    result1 = torch.empty(batch_size, seq_len, d_k)\n",
    "    result1[..., 0::2] = x_even_rot  # Fill positions 0, 2, 4, ...\n",
    "    result1[..., 1::2] = x_odd_rot   # Fill positions 1, 3, 5, ...\n",
    "    print(f\"Result1 shape: {result1.shape}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"METHOD 2: Stack + flatten (your approach fixed)\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    stacked = torch.stack([x_even_rot, x_odd_rot], dim=-1)  # (..., seq_len, d_k/2, 2)\n",
    "    result2 = stacked.flatten(-2)  # Flatten last 2 dims: (..., seq_len, d_k)\n",
    "    print(f\"Stacked shape: {stacked.shape}\")\n",
    "    print(f\"Result2 shape: {result2.shape}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"METHOD 3: Stack + reshape\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    stacked = torch.stack([x_even_rot, x_odd_rot], dim=-1)\n",
    "    result3 = stacked.reshape(*stacked.shape[:-2], d_k)\n",
    "    print(f\"Result3 shape: {result3.shape}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"METHOD 4: Concatenate + rearrange (using einops)\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    from einops import rearrange\n",
    "    \n",
    "    # Stack along a new dimension, then rearrange\n",
    "    stacked = torch.stack([x_even_rot, x_odd_rot], dim=-1)  # (..., d_k/2, 2)\n",
    "    result4 = rearrange(stacked, '... pairs two -> ... (pairs two)')\n",
    "    print(f\"Result4 shape: {result4.shape}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"METHOD 5: Interleave using repeat_interleave\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # This doesn't work directly but shows the concept\n",
    "    # We'd need to manually interleave, which is essentially method 1\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"VERIFICATION: All methods give same result?\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    print(f\"Method 1 == Method 2: {torch.allclose(result1, result2)}\")\n",
    "    print(f\"Method 1 == Method 3: {torch.allclose(result1, result3)}\")\n",
    "    print(f\"Method 1 == Method 4: {torch.allclose(result1, result4)}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"ELEMENT ORDER VERIFICATION\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Check that the elements are in the right order\n",
    "    print(\"First few elements of result1:\")\n",
    "    print(\"Should be: even[0], odd[0], even[1], odd[1], even[2], odd[2]\")\n",
    "    print(f\"result1[0, 0, :]: {result1[0, 0, :]}\")\n",
    "    print(f\"x_even_rot[0, 0, :]: {x_even_rot[0, 0, :]}\")\n",
    "    print(f\"x_odd_rot[0, 0, :]: {x_odd_rot[0, 0, :]}\")\n",
    "\n",
    "demo_merge_techniques()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5ef440c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(0, 30)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7a9c8ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import rearrange, einsum, reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "31da0087",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 3]), torch.Size([4, 3]))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = torch.tensor([[1,2,3],[6, 8, 10]])\n",
    "key = torch.tensor([[-1,-2,-3],[6, 8, 10], [-3, 2, -1], [8, 4, 0]])\n",
    "query.size(), key.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "353c7d76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.9799,  7.3539, -0.2828,  2.2627],\n",
       "        [-7.3539, 28.2843, -1.6971, 11.3137]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = einsum(query, key, \"... q_len d_k, ... k_len d_k -> ... q_len k_len\") / torch.sqrt(torch.tensor(d_k, dtype=query.dtype))\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8d9bdb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "logits_2d = torch.randn(5, 10)  # (batch_size, vocab_size)\n",
    "targets_2d = torch.randint(0, 10, (5,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89329bad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.9269,  1.4873,  0.9007, -2.1055,  0.6784, -1.2345, -0.0431, -1.6047,\n",
       "         -0.7521,  1.6487],\n",
       "        [-0.3925, -1.4036, -0.7279, -0.5594, -0.7688,  0.7624,  1.6423, -0.1596,\n",
       "         -0.4974,  0.4396],\n",
       "        [-0.7581,  1.0783,  0.8008,  1.6806,  1.2791,  1.2964,  0.6105,  1.3347,\n",
       "         -0.2316,  0.0418],\n",
       "        [-0.2516,  0.8599, -1.3847, -0.8712,  0.0780,  0.5258, -0.4880,  1.1914,\n",
       "         -0.8140, -0.7360],\n",
       "        [-0.8371, -0.9224, -0.0635,  0.6756, -0.0978,  1.8446, -1.1845,  1.3835,\n",
       "         -1.2024,  0.7078]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f97a25a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 0, 1, 1, 7])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d88dd35f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.9269],\n",
       "        [1.6423],\n",
       "        [1.6806],\n",
       "        [1.1914],\n",
       "        [1.8446]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_logits = torch.max(logits_2d, dim=1, keepdim=True)[0]\n",
    "max_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf3c856d",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits_stable = logits_2d - max_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "909c8a5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.2072, 0.9042, 1.5671, 1.2431, 1.0228])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_sum_exp = torch.log(torch.sum(torch.exp(logits_stable), dim=1))\n",
    "log_sum_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bbe667c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-4.0324, -2.0348, -0.6023, -0.3315, -0.4610])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_logits = logits_stable[torch.arange(logits_stable.shape[0]), targets_2d]\n",
    "target_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e591b424",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([0, 1, 2, 3, 4]), tensor([3, 0, 1, 1, 7])]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[torch.arange(logits_stable.shape[0]), targets_2d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0b8bc814",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 10, 1]), torch.Size([5, 10]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits_stable.unsqueeze(-1).shape, logits_stable.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934e8ccd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8c861c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections.abc import Callable, Iterable\n",
    "from typing import Optional\n",
    "import torch\n",
    "import math\n",
    "class SGD(torch.optim.Optimizer):\n",
    "    def __init__(self, params, lr=1e-3):\n",
    "        if lr < 0:\n",
    "            raise ValueError(f\"Invalid learning rate: {lr}\")\n",
    "        defaults = {\"lr\": lr}\n",
    "        super().__init__(params, defaults)\n",
    "    def step(self, closure: Optional[Callable] = None):\n",
    "        loss = None if closure is None else closure()\n",
    "        for group in self.param_groups:\n",
    "            lr = group[\"lr\"] # Get the learning rate.\n",
    "            for p in group[\"params\"]:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                state = self.state[p] # Get state associated with p.\n",
    "                t = state.get(\"t\", 0) # Get iteration number from the state, or initial value.\n",
    "                grad = p.grad.data # Get the gradient of loss with respect to p.\n",
    "                p.data -= lr / math.sqrt(t + 1) * grad # Update weight tensor in-place.\n",
    "                state[\"t\"] = t + 1 # Increment iteration number.\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ffbc2fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.302330017089844\n",
      "20.458757400512695\n",
      "19.884187698364258\n",
      "19.42763328552246\n",
      "19.04102325439453\n",
      "18.701929092407227\n",
      "18.397775650024414\n",
      "18.120677947998047\n",
      "17.865320205688477\n",
      "17.627910614013672\n",
      "17.405637741088867\n",
      "17.196352005004883\n",
      "16.99835777282715\n",
      "16.810300827026367\n",
      "16.631071090698242\n",
      "16.459749221801758\n",
      "16.295564651489258\n",
      "16.137855529785156\n",
      "15.986066818237305\n",
      "15.839704513549805\n",
      "15.698347091674805\n",
      "15.56161880493164\n",
      "15.429190635681152\n",
      "15.300771713256836\n",
      "15.176095962524414\n",
      "15.05492877960205\n",
      "14.937060356140137\n",
      "14.822297096252441\n",
      "14.710461616516113\n",
      "14.601398468017578\n",
      "14.49496078491211\n",
      "14.391012191772461\n",
      "14.289432525634766\n",
      "14.190107345581055\n",
      "14.092930793762207\n",
      "13.997806549072266\n",
      "13.904642105102539\n",
      "13.81335735321045\n",
      "13.723869323730469\n",
      "13.63610553741455\n",
      "13.550000190734863\n",
      "13.465487480163574\n",
      "13.3825044631958\n",
      "13.300997734069824\n",
      "13.220909118652344\n",
      "13.142192840576172\n",
      "13.064800262451172\n",
      "12.98868179321289\n",
      "12.913800239562988\n",
      "12.840112686157227\n",
      "12.76758098602295\n",
      "12.69616985321045\n",
      "12.625840187072754\n",
      "12.556562423706055\n",
      "12.48830795288086\n",
      "12.421039581298828\n",
      "12.354736328125\n",
      "12.2893648147583\n",
      "12.224903106689453\n",
      "12.161325454711914\n",
      "12.09860610961914\n",
      "12.036722183227539\n",
      "11.975652694702148\n",
      "11.91537857055664\n",
      "11.855875015258789\n",
      "11.797126770019531\n",
      "11.739112854003906\n",
      "11.681816101074219\n",
      "11.625219345092773\n",
      "11.569306373596191\n",
      "11.514060020446777\n",
      "11.459467887878418\n",
      "11.405509948730469\n",
      "11.352176666259766\n",
      "11.299450874328613\n",
      "11.247322082519531\n",
      "11.19577407836914\n",
      "11.144797325134277\n",
      "11.094379425048828\n",
      "11.044507026672363\n",
      "10.995168685913086\n",
      "10.946355819702148\n",
      "10.898056983947754\n",
      "10.850261688232422\n",
      "10.802957534790039\n",
      "10.756138801574707\n",
      "10.709794044494629\n",
      "10.663914680480957\n",
      "10.618492126464844\n",
      "10.573517799377441\n",
      "10.528983116149902\n",
      "10.484880447387695\n",
      "10.441201210021973\n",
      "10.397936820983887\n",
      "10.355081558227539\n",
      "10.312629699707031\n",
      "10.2705717086792\n",
      "10.228900909423828\n",
      "10.18761157989502\n",
      "10.146697044372559\n"
     ]
    }
   ],
   "source": [
    "weights = torch.nn.Parameter(5 * torch.randn((10, 10)))\n",
    "opt = SGD([weights], lr=1)\n",
    "for t in range(100):\n",
    "    opt.zero_grad() # Reset the gradients for all learnable parameters.\n",
    "    loss = (weights**2).mean() # Compute a scalar loss value.\n",
    "    if t//10 == 0:\n",
    "        print(loss.cpu().item())\n",
    "    loss.backward() # Run backward pass, which computes gradients.\n",
    "    opt.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d2a44f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
